{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modelling - Ladder Score Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "Split the data into train, test, validation, and cross-validation datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# * Train dataset includes all years before 2015\n",
    "# * Test dataset includes years between 2016 and 2018\n",
    "# * Validation dataset includes years after 2019\n",
    "# * Cross-validation dataset includes all the years available\n",
    "\n",
    "df = pd.read_csv(\"data/imputed-data.csv\")\n",
    "df.drop(['kmean group', 'Status'], axis=1, inplace=True)\n",
    "df['Year'] = df['Year'].astype('int')\n",
    "\n",
    "model_df = df.copy(deep=True)\n",
    "model_df['Country name'] = pd.factorize(model_df['Country name'])[0]\n",
    "model_df['Regional indicator'] = pd.factorize(model_df['Regional indicator'])[0]\n",
    "\n",
    "train = model_df[model_df['Year'] <= 2015].copy(deep=True)\n",
    "train_y = train['Ladder score']\n",
    "train.drop(['Ladder score'], axis=1, inplace=True)\n",
    "\n",
    "test = model_df[(model_df['Year'] > 2015) & (df['Year'] < 2019)].copy(deep=True)\n",
    "test_y = test['Ladder score']\n",
    "test.drop(['Ladder score'], axis=1, inplace=True)\n",
    "\n",
    "val = model_df[model_df['Year'] > 2019].copy(deep=True)\n",
    "val_y = val['Ladder score']\n",
    "val.drop(['Ladder score'], axis=1, inplace=True)\n",
    "\n",
    "cv_train = model_df.copy(deep=True)\n",
    "cv_train_y = model_df['Ladder score']\n",
    "cv_train.drop(['Ladder score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/imputed-data.csv\")\n",
    "df.drop(['kmean group', 'Status'], axis=1, inplace=True)\n",
    "df['Year'] = df['Year'].astype('int')\n",
    "\n",
    "model_df = df.copy(deep=True)\n",
    "model_df['Country name'] = pd.factorize(model_df['Country name'])[0]\n",
    "model_df['Regional indicator'] = pd.factorize(model_df['Regional indicator'])[0]\n",
    "\n",
    "X_train, test, y_train, test_y = train_test_split(model_df.drop(['Ladder score'], axis=1), model_df['Ladder score'], test_size=0.2, random_state=1234)\n",
    "train, val, train_y, val_y = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "cv_train = model_df.copy(deep=True)\n",
    "cv_train_y = model_df['Ladder score']\n",
    "cv_train.drop(['Ladder score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "* Parameters are not optimal values, but rather included in this section as proof-of-concept\n",
    "* Given a need for a more accurate predictive regression model, optimal parameters would have been selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Regressor MAE: 0.1991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best XGBoost Parameters from Grid Search CV: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 500, 'objective': 'reg:squarederror', 'subsample': 0.7}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def XGBoost_Tuning(train, train_y):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           scoring = 'neg_mean_absolute_error',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = False)\n",
    "    \n",
    "    gsearch.fit(train,train_y)\n",
    "\n",
    "    return gsearch.best_params_\n",
    "\n",
    "\n",
    "xgb_tuned_params = XGBoost_Tuning(train, train_y)\n",
    "tuned_xgb = XGBRegressor(**xgb_tuned_params)\n",
    "tuned_xgb.fit(train, train_y)\n",
    "tuned_xgb_preds = tuned_xgb.predict(test)\n",
    "print(f'Tuned XGBoost Regressor MAE: {mean_absolute_error(test_y, tuned_xgb_preds):.4f}')\n",
    "display(f'Best XGBoost Parameters from Grid Search CV: {xgb_tuned_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Regressor MAE: 0.2040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best LightGBM Parameters from Grid Search CV: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'n_estimators': 500, 'num_leaves': 60, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.5}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LightGBM_Tuning(train, train_y):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 60, 100],\n",
    "        'reg_alpha': [0, 0.1, 0.5],\n",
    "        'reg_lambda': [0, 0.1, 0.5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500]\n",
    "    }\n",
    "\n",
    "    lgb_model = LGBMRegressor()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = lgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           scoring = 'neg_mean_absolute_error',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = False)\n",
    "    \n",
    "    gsearch.fit(train,train_y)\n",
    "\n",
    "    return gsearch.best_params_\n",
    "\n",
    "lgb_tuned_params = LightGBM_Tuning(train, train_y)\n",
    "tuned_lgb = LGBMRegressor(**lgb_tuned_params)\n",
    "tuned_lgb.fit(train, train_y)\n",
    "tuned_lgb_preds = tuned_lgb.predict(test)\n",
    "print(f'Tuned XGBoost Regressor MAE: {mean_absolute_error(test_y, tuned_lgb_preds):.4f}')\n",
    "display(f'Best LightGBM Parameters from Grid Search CV: {lgb_tuned_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV & Test Set Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(), Ridge(), SVR(), XGBRegressor(), XGBRegressor(**xgb_tuned_params), LGBMRegressor(), LGBMRegressor(**lgb_tuned_params)]\n",
    "model_name = ['LR', 'Ridge', 'SVM', 'XGBoost', 'Tuned XGBoost','LightGBM',  'Tuned LightGBM']\n",
    "test_model_summary = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    cv_scores = cross_val_score(model, cv_train, cv_train_y, cv=10, scoring = 'neg_mean_absolute_error')\n",
    "    cv_mae = abs(cv_scores).mean()\n",
    "\n",
    "    model.fit(train, train_y)\n",
    "    preds = model.predict(test)\n",
    "    tts_mae = mean_absolute_error(test_y, preds)\n",
    "    \n",
    "    model_score = pd.DataFrame([model_name[i], cv_mae, tts_mae]).transpose()\n",
    "    test_model_summary.append(model_score)\n",
    "    \n",
    "test_model_summary = pd.concat(test_model_summary)\n",
    "test_model_summary.reset_index(inplace=True, drop=True)\n",
    "test_model_summary.columns = ['Model', 'CV Score', 'Test Set Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = train.append(test)\n",
    "final_train_y = train_y.append(test_y)\n",
    "\n",
    "val_model_summary = []\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    model.fit(final_train, final_train_y)\n",
    "    preds = model.predict(val)\n",
    "    tts_mae = mean_absolute_error(val_y, preds)\n",
    "    \n",
    "    model_score = pd.DataFrame([model_name[i], tts_mae]).transpose()\n",
    "    val_model_summary.append(model_score)\n",
    "    \n",
    "val_model_summary = pd.concat(val_model_summary)\n",
    "val_model_summary.reset_index(inplace=True, drop=True)\n",
    "val_model_summary.columns = ['Model', 'Validation Set Score']\n",
    "\n",
    "model_table = pd.merge(test_model_summary, val_model_summary, on='Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model Scores\n",
    "* Note: Ensemble model used a weighted average of untuned LightGBM and XGBoost models, producing a more accurate result than either individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMRegressor()\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "lgb_model.fit(train, train_y)\n",
    "lgb_preds = lgb_model.predict(test)\n",
    "\n",
    "xgb_model.fit(train, train_y)\n",
    "xgb_preds = xgb_model.predict(test)\n",
    "\n",
    "ensemble_preds = (lgb_preds*0.5) + (xgb_preds*0.5)\n",
    "test_ensemble_score = mean_absolute_error(test_y, ensemble_preds)\n",
    "\n",
    "lgb_model.fit(final_train, final_train_y)\n",
    "lgb_preds = lgb_model.predict(val)\n",
    "\n",
    "xgb_model.fit(final_train, final_train_y)\n",
    "xgb_preds = xgb_model.predict(val)\n",
    "\n",
    "ensemble_preds = (lgb_preds*0.5) + (xgb_preds*0.5)\n",
    "val_ensemble_score = mean_absolute_error(val_y, ensemble_preds)\n",
    "\n",
    "ensemble_summary = pd.DataFrame(['Ensemble (Untuned XGBoost + LightGBM)', 'NA', test_ensemble_score, val_ensemble_score]).transpose()\n",
    "ensemble_summary.columns = ['Model', 'CV Score', 'Test Set Score', 'Validation Set Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score</th>\n",
       "      <th>Test Set Score</th>\n",
       "      <th>Validation Set Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.337919</td>\n",
       "      <td>0.293462</td>\n",
       "      <td>0.344255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.337984</td>\n",
       "      <td>0.293436</td>\n",
       "      <td>0.343823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.437695</td>\n",
       "      <td>0.431099</td>\n",
       "      <td>0.440702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.359812</td>\n",
       "      <td>0.207848</td>\n",
       "      <td>0.228388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned XGBoost</td>\n",
       "      <td>0.350024</td>\n",
       "      <td>0.199123</td>\n",
       "      <td>0.220393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.350588</td>\n",
       "      <td>0.201355</td>\n",
       "      <td>0.220094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned LightGBM</td>\n",
       "      <td>0.374846</td>\n",
       "      <td>0.20397</td>\n",
       "      <td>0.229669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble (Untuned XGBoost + LightGBM)</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.198037</td>\n",
       "      <td>0.218025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  CV Score Test Set Score  \\\n",
       "0                                     LR  0.337919       0.293462   \n",
       "1                                  Ridge  0.337984       0.293436   \n",
       "2                                    SVM  0.437695       0.431099   \n",
       "3                                XGBoost  0.359812       0.207848   \n",
       "4                          Tuned XGBoost  0.350024       0.199123   \n",
       "5                               LightGBM  0.350588       0.201355   \n",
       "6                         Tuned LightGBM  0.374846        0.20397   \n",
       "7  Ensemble (Untuned XGBoost + LightGBM)        NA       0.198037   \n",
       "\n",
       "  Validation Set Score  \n",
       "0             0.344255  \n",
       "1             0.343823  \n",
       "2             0.440702  \n",
       "3             0.228388  \n",
       "4             0.220393  \n",
       "5             0.220094  \n",
       "6             0.229669  \n",
       "7             0.218025  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_table = pd.concat([model_table, ensemble_summary], axis=0, ignore_index=True)\n",
    "final_model_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
